# ğŸ¤– Guide d'installation et utilisation d'Ollama

## Installation Ollama

### Windows
1. TÃ©lÃ©charger Ollama : https://ollama.com/download/windows
2. Installer l'application
3. Ollama dÃ©marre automatiquement en arriÃ¨re-plan

### VÃ©rifier l'installation
```powershell
ollama --version
```

## TÃ©lÃ©charger un modÃ¨le

### ModÃ¨les recommandÃ©s :

#### 1. Llama 3.2 (3B) - **RECOMMANDÃ‰** (rapide, efficace)
```powershell
ollama pull llama3.2
```

#### 2. Mistral (7B) - (trÃ¨s bon, un peu plus lent)
```powershell
ollama pull mistral
```

#### 3. Phi-3 (3.8B) - (compact, rapide)
```powershell
ollama pull phi3
```

## DÃ©marrer Ollama (si pas dÃ©marrÃ©)
```powershell
ollama serve
```

## Tester Ollama
```powershell
ollama run llama3.2
```

## Configuration dans l'API

Le fichier `app/analyse_intelligente.py` est configurÃ© pour utiliser **llama3.2**.

Pour changer de modÃ¨le, modifiez la ligne :
```python
OLLAMA_MODEL = "llama3.2"  # ou "mistral", "phi3", etc.
```

## Utilisation dans l'API

### L'IA est appelÃ©e automatiquement pour :

1. **Zones sous-vaccinÃ©es** : Recommandations pour chaque rÃ©gion prioritaire
2. **PrÃ©diction besoins** : StratÃ©gie globale de commande
3. **Optimisation distribution** : Actions concrÃ¨tes anti-gaspillage
4. **PrÃ©diction urgences** : StratÃ©gies de rÃ©duction

### Si Ollama n'est pas disponible :
- L'API fonctionne quand mÃªme
- Message affichÃ© : "âš ï¸ Ollama non disponible"
- Les analyses statistiques restent complÃ¨tes

## Performance

| ModÃ¨le | Taille | Vitesse | QualitÃ© |
|--------|--------|---------|---------|
| llama3.2 | 3B | âš¡âš¡âš¡ | â­â­â­â­ |
| phi3 | 3.8B | âš¡âš¡âš¡ | â­â­â­ |
| mistral | 7B | âš¡âš¡ | â­â­â­â­â­ |

## Test rapide de l'intÃ©gration

```powershell
# 1. DÃ©marrer Ollama
ollama serve

# 2. Dans un autre terminal, tester l'API
curl http://localhost:11434/api/generate -d '{
  "model": "llama3.2",
  "prompt": "Bonjour, teste 1-2-3",
  "stream": false
}'
```

## DÃ©sactiver l'IA (mode sans Ollama)

Si vous voulez dÃ©sactiver complÃ¨tement l'IA, dans `analyse_intelligente.py` :

```python
def appeler_agent_ia(prompt: str, temperature: float = 0.7) -> str:
    return "IA dÃ©sactivÃ©e"
```

